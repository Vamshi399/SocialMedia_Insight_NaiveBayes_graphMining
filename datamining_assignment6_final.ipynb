{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"datamining_assignment6_final.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Fdh4gvsOPMJV"},"source":["import twitter\n","import json\n","consumer_key = \"xzSXE5Fvx1ZL6P6PUNwXg56Ff\"\n","consumer_secret = \"9IgUnHkE2Pn0Di2v8HySatcryxuW6QtU7YNNJITT76LZM0puIP\"\n","access_token = \"393277154-vVEflsJ6aLcOUg8eJ9K8TBo1vMsJiYd9btPKv3p5\"\n","access_token_secret = \"iHR5QYIrOZ2v1mrvW20PjrpNcIvDNYmdorYpZHmz1HtXS\"\n","authorization = twitter.OAuth(access_token, access_token_secret, consumer_key, consumer_secret)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryIC_rk1PMJg"},"source":["import os\n","output_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_tweets.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7uGlsvkPMJo","outputId":"8bdbfaa0-3c03-4124-f4f1-14f18503a9bf"},"source":["t = twitter.Twitter(auth=authorization)\n","import json\n","with open(output_filename, 'a') as output_file:\n","    search_results = t.search.tweets(q=\"python\", count=1000)['statuses']\n","    for tweet in search_results:\n","        if 'text' in tweet:\n","            print(tweet['user']['screen_name'])\n","            print(tweet['text'])\n","            print()\n","            output_file.write(json.dumps(tweet))\n","            output_file.write(\"\\n\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LlnuxBot\n","RT @oaksjp: ã‚¢ãƒ¡ãƒ–ãƒ­ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ ã€Apache2.2ã§python2.7ã®mod_wsgiã‚’å‹•ã‹ã™ã€ #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","hatebu100\n","ã‚ãªãŸã® Window 10 ã«ã¯ä½•ç¨®é¡ã® Python ãŒå…¥ã£ã¦ã„ã¾ã™ã‹ï¼Ÿç§ã¯5ç¨®é¡ã§ã—ãŸãŒã€‚ - Qiita\n","https://t.co/OAuCDa1wnV\n","https://t.co/5GrXpvBJM9\n","ã‚¿ã‚¤ãƒˆãƒ«ã¯ç…½ã‚Šã§ã™ã€‚â€¦ https://t.co/NYT7Ntgqfl\n","\n","Jeraylia_Takudo\n","RT @oaksjp: ã‚¢ãƒ¡ãƒ–ãƒ­ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ ã€Apache2.2ã§python2.7ã®mod_wsgiã‚’å‹•ã‹ã™ã€ #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","avimimoun\n","RT @Radarinfo01: Online Courses - The Ultimate Beginner's Guide to Django 1.11 -&gt; https://t.co/IjSLDD9HhC\n","\n","#100DaysOfCode #html5 #NodeJs #Aâ€¦\n","\n","kreutznaer2\n","RT @ethantenison: Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it automated tâ€¦\n","\n","oaksjp\n","ã‚¢ãƒ¡ãƒ–ãƒ­ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ ã€Apache2.2ã§python2.7ã®mod_wsgiã‚’å‹•ã‹ã™ã€ #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","smaiitm\n","RT @gp_pulipaka: GANs Make an Entry Into High Energy Physics. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Pyâ€¦\n","\n","learn__together\n","RT @ethantenison: Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it automated tâ€¦\n","\n","kreutznaer2\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","acobra334\n","@RealJamesWoods Monty Python ...omg\n","\n","ethantenison\n","Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it automâ€¦ https://t.co/4Fc2zodV6a\n","\n","cool_python\n","RT @realpython: Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","akdm_bot\n","RT @gp_pulipaka: GANs Make an Entry Into High Energy Physics. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Pyâ€¦\n","\n","tanakafreelance\n","ã€Œãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã™ãŒã€å­¦ã¼ã†ã¨æ€ã†ã¨é«˜åº¦ãªæ•°å­¦çŸ¥è­˜ã®å¿…è¦æ€§ã«æ„æ¬²ã‚’æŒ«ã‹ã‚Œã‚‹ã“ã¨ãŒå°‘ãªãã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬æ›¸ã¯ãã‚“ãªæ–¹ã®ãŸã‚ã«ã€é«˜æ ¡ãƒ¬ãƒ™ãƒ«ã®æ•°å­¦ã¨Pythonã®åŸºæœ¬ã ã‘ã‚’å‰æã«ã€å®Ÿéš›ã«ä½¿ãˆã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å­¦ã¶ãŸã‚ã®å…¥é–€æ›¸ã§ã™â€¦ https://t.co/dP82ANUPEo\n","\n","MFuturetech\n","RT @gp_pulipaka: Implement Image classification by TensorFlow. #BigData #Analytics #DataScience #AI #MachineLearning #ComputerVision #IoT #â€¦\n","\n","avimimoun\n","RT @jorgardev: React Styled Components: Inline Styles + 3 Other CSS Styling Approaches (with examples)\n","\n","#programming #programmer #developerâ€¦\n","\n","Comatose_D\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","AkiGlobe\n","@inu_love_global ãã®æ°—æŒã¡ã€ã‚ã‹ã‚Šã¾ã™ã€‚åƒ•ã‚‚Itæ¥­ç•Œã«å…¥ã£ã¦SQLã¨Pythonã‚’ã‚„ã‚Šå§‹ã‚ã¾ã—ãŸã€‚\n","\n","SQLã§ãã‚‹ã¨ã„ã‚ã„ã‚ã¨ãƒ‡ãƒ¼ã‚¿å¼•ãå‡ºã—ã¦ã“ã‚Œã¦ã€æ¥½ã—ã„ã§ã™ã‚ˆã€‚ãƒŸãƒƒã‚¯ã•ã‚“ã®å‚è€ƒæ›¸ãŒå€‹äººçš„ã«ã¯ãŠã™ã™ã‚ã§ã™ãƒ¼ã€‚\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","codedailybot\n","RT @iphonegalaxymd: When you are constantly anxious but you don't know why \n","\n","#codingÂ #programmingÂ #programmerÂ #code #developerÂ #javaÂ #coderâ€¦\n","\n","RaymondWSA460\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineLâ€¦\n","\n","StormBear\n","Excellent article: #Python is eating the world: How one developer's side project became the hottest programming lanâ€¦ https://t.co/Luc4wmCZJR\n","\n","Mike6338501\n","@RealJamesWoods You two are on another level with the Monty Python reference. Hadnâ€™t seen that clip in a long time. Still funny.\n","\n","jasonhbush\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Drâ€¦\n","\n","DeepSingularity\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineLâ€¦\n","\n","blackgaygemini\n","hmm maybe this summer I will figure out what \"digital humanities\" is/are and perhaps also become comfortable with Python\n","\n","Taieb_Bot\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineLâ€¦\n","\n","BigDataConda\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineLâ€¦\n","\n","TheVeryHighKing\n","#Python #RaspberryPi #SpeedTest #Matplotlib https://t.co/SGpHXSnKaY\n","\n","TheVeryHighKing\n","Hourly average speed test results\n","-DL(Mb/s): 69.84 (max:70.20/min:69.30)\n","-UL(Mb/s): 19.39 (max:20.30/min:17.50)\n","-Piâ€¦ https://t.co/3DPFi4pmAH\n","\n","gp_pulipaka\n","AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AIâ€¦ https://t.co/DaGMM2bHw5\n","\n","b4yu4ddi\n","RT @python_planet: Python Pandas Tutorial (Part 6): Add/Remove Rows and Columns From DataFrames\n","\n","â˜ https://t.co/xWX3NdAXaN\n","\n","#python #prograâ€¦\n","\n","SorbiG\n","@patmon110 @xUndeadPikachu @desimojito @elonmusk No, I assume an octopus to be larger than the tiny mouth of that Aâ€¦ https://t.co/8CYsKthsIF\n","\n","ddbelcher\n","RT @realpython: Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","Mikelio_7\n","å‰ã«è–¬å‰¤å¸«ã¨ä»˜ãåˆã£ãŸæ™‚ã«ã€å…±é€šè¨€èªã¿ãŸã„ãªã‚‚ã®ãŒç„¡ãã¦çµå±€ã™ãåˆ¥ã‚Œã¡ã‚ƒã£ãŸã‚“ã§ã™ã‚ˆã€è‡ªåˆ†ãŒå¤§å¤‰ãªæ™‚ã«åˆ†ã‹ã£ã¦ã‚‚ã‚‰ãˆãªã‹ã£ãŸã‚Šã—ã¦ã€åƒ•ã¯Pythonã§ã‚‚Javaã§ã‚‚ã‚ˆã‹ã£ãŸã‚“ã§ã™ã‘ã©\n","\n","xaelbot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","avimimoun\n","RT @ThePSF: Ontario Authors Python Group, Feb. 25 - Hobby Robotics with Nvidia Jetson Nano. Gerhard Roth covers what can be done with smallâ€¦\n","\n","learn__together\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","k_can_python\n","@_L_6_ çœŸå‰£ã«ã‚„ã£ã¦ã„ã“ã†ãª\n","\n","Taieb_Bot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3â€¦\n","\n","thepydtyper\n","R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack ğŸ¤˜ https://t.co/f3Tu5LoUvf\n","\n","subreddit_py\n","|Python World| Tutorials/Tips/Tricks for Python. https://t.co/9bivm3NER3\n","\n","BeardySmeardy\n","#Spectrum My #InternetSpeed :\n","Ping: 40.58 ms\n","Download: 198.71 Mbit/s\n","Upload: 10.92 Mbit/s\n","#automagic #python #corporateaccountability\n","\n","tomo_matsushi\n","ScalaãŒè¡°é€€ã—ã¦ã‚‹ã¨ã‹ã®è©±ã¯ã“ã®æ–¹ãŒç™ºç«¯ï¼Ÿ\n","Scalaãƒ¦ãƒ¼ã‚¶ãŒJavaãƒ¦ãƒ¼ã‚¶ã‚„Pythonãƒ¦ãƒ¼ã‚¶ãã‚‰ã„ã«ãªã£ãŸã‚‰ç››ã‚Šä¸ŠãŒã£ãŸï¼\n","ãªã®ã§ã€ãã‚‚ãã‚‚ç››ã‚Šä¸ŠãŒã£ã¦ãªã„ã‚‚ã®ã‚’è¡°é€€ã—ãŸã£ã¦ã®ã‚‚ã­â€¥\n","è¨€èªã¨ã—ã¦ã¯å¾Œåˆã®Scalaã®ã»ã†ãŒç´ â€¦ https://t.co/J9PJ778kFt\n","\n","k_can_python\n","@yamada_marumaru ãŠã¯ã‚ˆğŸ’•\n","\n","Deep_In_Depth\n","Large Scale Training at BAIR with Ray Tune https://t.co/0o5JfUG1kJ #DeepLearning #NeuralNetworksâ€¦ https://t.co/zg40VHIo9I\n","\n","nondakure180\n","Python + Excel ã«èˆˆå‘³ã‚ã‚Š\n","\n","Cryptocristian\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic raâ€¦\n","\n","jorgardev\n","React Styled Components: Inline Styles + 3 Other CSS Styling Approaches (with examples)\n","\n","#programming #programmerâ€¦ https://t.co/wQT5MtNZRG\n","\n","AlmanafSivi\n","RT @KirkDBorne: Must get this â€œML from A to Zâ€ book â€” I now have my copy &amp; I love it! &gt;&gt; \"Mastering #MachineLearning #Algorithms\" (2nd Editâ€¦\n","\n","FullstackDevJS\n","Shopyo: Enhance Your Flask by Exploring An Advanced Flask App #Fullstack #Javascript #Angular #React #Python https://t.co/zjdcke8dik\n","\n","realpython\n","Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","avimimoun\n","RT @ThePSF: Boulder, CO Python Meetup March 10 - Boulder, CO. Talks include: Keeping credentials safe in the GitHub age (Matt Bacchi) &amp; Usiâ€¦\n","\n","ProgramWithUsNY\n","pandas_merge with inner join \n"," \n","#programwithus #python https://t.co/k0JNSa6uLg\n","\n","umibedessk\n","âœï¸ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’12æ—¥ç›®âœï¸\n","ã¤ã¾ã‚‰ãªã„ã¨æ€ã£ã¦å­¦ç¿’ã™ã‚‹ã¨ã€è„³ã‚‚ä¸å¿…è¦ãªæƒ…å ±ã¨åˆ¤æ–­ã—ã¦ã—ã¾ã£ã¦è¨˜æ†¶ã®å®šç€ãŒã—ã«ãããªã‚‹ãã†ã§ã™ã€‚\n","èˆˆå‘³ã‚’æŒã£ã¦å­¦ç¿’ã‚’ã—ã¦ã„ãã¾ã™ï¼\n","\n","#ä»Šæ—¥ã®ç©ã¿ä¸Šã’\n","ğŸ‘‰Python\n","ğŸ‘‰Progate\n","ğŸ‘‰èª­æ›¸â€¦ https://t.co/TgbWJS4Hm0\n","\n","Softtek\n","#Python continues to be the favorite #programming language among #developers https://t.co/lS797ClZ8z\n","\n","orekyuu\n","æŸã‚†ãƒ¼ã¡ã‚…ãƒ¼ã°ãƒ¼ãŒScala disã—ã¦ã‚‹ã¨èã„ã¦è¦‹ã¦ã¿ãŸã‘ã©ã€äººå£ãŒå³è‚©ä¸‹ãŒã‚Šã«ãªã£ãŸè¨€èªãŒã¾ãŸã‚‚ã©ã‚‹ã“ã¨ã¯éå»ã®ä¾‹ã‹ã‚‰ã‚‚ã¾ãšãªã„ã£ã¦è¨€ã†ã‘ã©ã€Pythonã¨ã‹ä¸€æ™‚æœŸRubyã«é£Ÿã‚ã‚ŒãŸã‘ã©ã€ä»Šã¾ãŸäººæ°—å‡ºã¦ã¾ã›ã‚“ï¼Ÿ\n","\n","HeresJolly\n","Burmese Python Sanders\n","\n","y_yunusa4\n","RT @faruqjada: Today our SPECIAL SESSION on Python for Data Science was successful.\n","#1m_AI_talents_in_10yrs https://t.co/DBqG27STby\n","\n","KC_Gosso\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Drâ€¦\n","\n","cool_python\n","RT @MrDataScience: The History of Top Programming Languages from 1965 to 2019! #Coding #DataScience #Analytics #IoT #Python\n","https://t.co/daâ€¦\n","\n","LlnuxBot\n","RT @oaksjp: ã‚¢ãƒ¡ãƒ–ãƒ­ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ ã€python2.7ã§mod_wsgiã‚’å‹•ã‹ã™ã€ #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","rstatstweet\n","RT @gp_pulipaka: Implement Image classification by TensorFlow. #BigData #Analytics #DataScience #AI #MachineLearning #ComputerVision #IoT #â€¦\n","\n","A_Retweeter_Boy\n","Realtime Bitcoin Track with Python.......\n","\n","#Python3 #Bitcoin #bitcoin \n","\n","@hackeroid_ @utsavtechie @stufflistingsâ€¦ https://t.co/L9CRg2KO4C\n","\n","HariSeldoon\n","RT @KirkDBorne: ğŸŒŸThe 3rd edition of this massive book is now here! &gt;&gt; â€œ#Python #MachineLearning â€” ML and #DeepLearning with Python, scikit-â€¦\n","\n","kaji_blog\n","ã€ #python å‚ç…§ ã€‘\n","\n","#ãƒ–ãƒ­ã‚°æ›´æ–°\n","\n","ä»Šå›ã¯pythonã«ãŠã‘ã‚‹å‚ç…§ã«ã¤ã„ã¦\n","\n","âœ…å‚ç…§ã®æ¦‚å¿µ\n","\n","âœ…å‚ç…§ã‚’\"æ¸¡ã™\"\n","\n","âœ…copy()ã€deepcopy()é–¢æ•°\n","\n","ã“ã®å‚ç…§ã‚’ç†è§£ã™ã‚‹ã¨ã€ãƒªã‚¹ãƒˆã‚„è¾æ›¸ã¸ã®è€ƒãˆæ–¹ãŒå¤§ããå¤‰ã‚ã‚Šã¾â€¦ https://t.co/p3rjbt0ZEa\n","\n","rsk0315_h4x\n","çŸ¥ã£ã¦ã‚‹ï¼ C ã«æ…£ã‚ŒãŸäººãŒ C é¢¨ã®ã‚³ãƒ¼ãƒ‰ã‚’ Python ã§æ›¸ã„ã¦æ±šããªã‚‹ã‚„ã¤ã ï¼\n","\n","DavFields\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic raâ€¦\n","\n","oaksjp\n","ã‚¢ãƒ¡ãƒ–ãƒ­ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ ã€python2.7ã§mod_wsgiã‚’å‹•ã‹ã™ã€ #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","AlmanafSivi\n","RT @gp_pulipaka: Measuring Compositional Generalization. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Pythonâ€¦\n","\n","vishn_u99\n","RT @Radarinfo01: Online Courses - The Ultimate Beginner's Guide to Django 1.11 -&gt; https://t.co/IjSLDD9HhC\n","\n","#100DaysOfCode #html5 #NodeJs #Aâ€¦\n","\n","JayInfoSec\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Drâ€¦\n","\n","thelovelymedusa\n","@MnFrost Ball Python!\n","\n","xdubyaa\n","RT @shelbylcole: Progressive digital job postings be like:\n","â„œğ”¢ğ”®ğ”²ğ”¦ğ”¯ğ”¢ğ”ªğ”¢ğ”«ğ”±ğ”°:\n","- 7+ years at campaigns or agencies\n","- copywriter \n","- video editer\n","-â€¦\n","\n","EmerensB\n","ã“ã®è¨˜äº‹ã«æ›°ã\n","https://t.co/b3jP56hJqb\n","\n","HTML,CSS,JS, Python ç­‰ã®æ¯”è¼ƒçš„\"easy\"ãªè¨€èªã¯4~6ãƒ¶æœˆã§åŸºç¤ã‚’ç¿’å¾—ã§ãã‚‹\n","\n","å€‹äººçš„ãªè§£é‡ˆã¯ã€Œãã‚Œãã‚‰ã„å‹‰å¼·ã—ãŸã‚‰æ—©ããƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºã«é€²ã‚‚ã†â€¦ https://t.co/VOUWew2w7c\n","\n","BSUPimp\n","RT @gp_pulipaka: Measuring Compositional Generalization. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Pythonâ€¦\n","\n","BlkHwk0ps\n","RT @advait_me: Logistic Regression : Part 1 : Machine Learning \n","#bigdata #data #deeplearning #tech #coding  #python #programming  #analyticâ€¦\n","\n","reversepython\n","RT @MrDataScience: The History of Top Programming Languages from 1965 to 2019! #Coding #DataScience #Analytics #IoT #Python\n","https://t.co/daâ€¦\n","\n","MFuturetech\n","RT @advait_me: Logistic Regression : Part 1 : Machine Learning \n","#bigdata #data #deeplearning #tech #coding  #python #programming  #analyticâ€¦\n","\n","task_c_lang\n","#Bot\n","#ëŒ€ë¦¬ê³¼ì œ\n","#ì»´ê³µê³¼ì œ\n","#ê³¼ì œ \n","#í”„ë¡œê·¸ë˜ë°\n","í”„ë¡œê·¸ë˜ë°ê³¼ì œ í•´ë“œë¦½ë‹ˆë‹¤.\n","ì €ë ´í•œ ê°€ê²©ì— í•´ë“œë¦¬ë‹ˆ ë§ì€ ì´ìš© ë¶€íƒë“œë¦½ë‹ˆë‹¤!\n","ìì„¸í•œ ë¬¸ì˜ëŠ” ë””ì— ì£¼ì„¸ìš”!!\n","ì£¼ë ¥ì€ ì•Œê³ ë¦¬ì¦˜ì´ê³ ,\n","ì–¸ì–´ëŠ” python,c ê°€ëŠ¥í•©ë‹ˆë‹¤.\n","\n","Vaelot1\n","RT @GaelVaroquaux: Pypi, the Python package repository, costs 800k$/month in hosting: the volume that it serves brings real costs. \n","\n","Side nâ€¦\n","\n","MD_Connolly\n","RT @shelbylcole: Progressive digital job postings be like:\n","â„œğ”¢ğ”®ğ”²ğ”¦ğ”¯ğ”¢ğ”ªğ”¢ğ”«ğ”±ğ”°:\n","- 7+ years at campaigns or agencies\n","- copywriter \n","- video editer\n","-â€¦\n","\n","masonrothman\n","RT @Keiko_geo: Something different this time. \"Interactive #maps on #python #JupyterNotebook\" #folium #ipyleaflet What else is out there? Dâ€¦\n","\n","PedPrac12\n","RT @Starkeneurosurg: CHILD NECK PYTHON: Parents reported there giant snake in neck. Fistula direct connection artery &amp; vein. Veins dilatedâ€¦\n","\n","Kazansky1\n","RT @f_calandra: Ã€ la rencontre des habitants du quartier Python-Duvernois. Nous avons Ã©changÃ© notamment sur les questions de propretÃ© et suâ€¦\n","\n","piasu_iyaring8\n","@haku_1123 ãã\n","ã¾ã Pythonã¾ã§è¡Œã‘ã¦ãªã„ã‘ã©w\n","\n","vlgermanov\n","RT @jpetazzo: I had bookmarked @nnja's talk about Python debugging a while ago, and I finally took the time to watch it. \n","\n","Video:\n","https://tâ€¦\n","\n","arch_update_bot\n","python-atspi 2.36.0-1 (any/Extra)\n","\"Python bindings for D-Bus AT-SPI\"\n","&lt;2020-03-08&gt;\n","\n","leidavirginia1\n","RT @CiscoDevNet: Building a network automation controller in Python.\n","https://t.co/EM91RBqrsw\n","Join @dmfigol  Sunday, March 8th, 6 PM CET. 1â€¦\n","\n","TDataScience\n","Finding cyclic patterns: a tutorial on how to implement STFT in Python by Tiago Silveira https://t.co/uU1UGKGZsX\n","\n","asa9no640511\n","RT @Cpp_Learning: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†(ãƒ©ã‚°ç‰¹å¾´é‡)ã«ã¤ã„ã¦ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’æ›¸ãã¾ã—ãŸã€‚\n","\n","pythonã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä»˜ãã§è§£èª¬ã—ã¦ã¾ã™ã®ã§ã€è‰¯ã‘ã‚Œã°å‚è€ƒã«ã—ã¦ä¸‹ã•ã„ã­ã€‚\n","\n","ã€æ©Ÿæ¢°å­¦ç¿’ã€‘æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç† -ãƒ©ã‚°ç‰¹å¾´é‡ä½œæˆ- https://t.co/cR0ftâ€¦\n","\n","haku_1123\n","@piasu_iyaring8 ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªï¼ŸPythonã¨ã‹ï¼Ÿ\n","\n","softqueerfeels\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Drâ€¦\n","\n","RauceWine\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic raâ€¦\n","\n","hubofml\n","RT @machinelearnflx: Unsupervised Machine Learning Hidden Markov Models in Python https://t.co/Yg3Zj81gHc  #machinelearning #ad\n","\n","0xhexhex\n","RT @machinelearnflx: Unsupervised Machine Learning Hidden Markov Models in Python https://t.co/Yg3Zj81gHc  #machinelearning #ad\n","\n","lululevi\n","RT @ajhtweeting: This Python style video editing is a hoot! I call this one \"Inside Trump's Head\". &lt;sound up&gt; #TrumpPeedHisPants #TrumpViruâ€¦\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C73gSQUEPMJy","outputId":"11e1948b-b97d-4f32-be78-6b1c5f80ba75"},"source":["n_output = 0\n","\n","with open(output_filename, 'a') as output_file:\n","    search_results = t.search.tweets(q=\"python\", count=1000)['statuses']\n","    for tweet in search_results:\n","        if 'text' in tweet:\n","            output_file.write(json.dumps(tweet))\n","            output_file.write(\"\\n\\n\")\n","            n_output += 1\n","\n","print(\"Saved {} entries\".format(n_output))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved 100 entries\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DIxRrZOrPMJ6"},"source":["import os\n","input_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_tweets.json\")\n","classes_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_classes.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_QGrY_3PMKC"},"source":["labels_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_classes.json\")\n","tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCG2B3CRPMKI","outputId":"e997d29a-1def-408b-e0e4-71b234cf7bb4"},"source":["tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))\n","print(\"Loaded {} tweets\".format(len(tweets)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 1500 tweets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZwkH_sv0PMKQ","outputId":"e7690c2d-8fc8-4112-aa67-a18c923e1d92"},"source":["tweet_sample = tweets\n","labels = []\n","if os.path.exists(classes_filename):\n","    with open(classes_filename) as inf:\n","        labels = json.load(inf)\n","print(len(labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_r89ZfFwPMKW"},"source":["def get_next_tweet():\n","    return tweets[len(labels)]['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RYqtVHJPMKd","outputId":"a7f195e5-972b-46b5-b983-13e321c08eac"},"source":["%%html\n","<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","\n","<script>\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_next_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n","\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","      if(e.which == 48) {\n","        // 0 pressed\n","        set_label(0);\n","        $(\"input#capture\").val(\"\");\n","      }else if (e.which == 49){\n","        // 1 pressed\n","        set_label(1);  \n","        $(\"input#capture\").val(\"\");\n","      }\n","});\n","\n","load_next_tweet();\n","</script>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","\n","<script>\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_next_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n","\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","      if(e.which == 48) {\n","        // 0 pressed\n","        set_label(0);\n","        $(\"input#capture\").val(\"\");\n","      }else if (e.which == 49){\n","        // 1 pressed\n","        set_label(1);  \n","        $(\"input#capture\").val(\"\");\n","      }\n","});\n","\n","load_next_tweet();\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HjczxBhGPMKo","outputId":"ff5b9a59-e544-49d5-f9ce-86879bfb469e"},"source":["%%javascript\n","\n","\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"BBBLEPYGPMKx","outputId":"4134a854-d18c-42c7-adf5-38e8a221deb0"},"source":["%%html\n","<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","<script>\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","  if(e.which == 48) {\n","    // 0 pressed\n","    set_label(0);\n","    $(\"input#capture\").val(\"\");\n","  }else if (e.which == 49){\n","    // 1 pressed\n","    set_label(1);  \n","    $(\"input#capture\").val(\"\");\n","  }\n","});\n","\n","load_next_tweet();\n","</script>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","<script>\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","  if(e.which == 48) {\n","    // 0 pressed\n","    set_label(0);\n","    $(\"input#capture\").val(\"\");\n","  }else if (e.which == 49){\n","    // 1 pressed\n","    set_label(1);  \n","    $(\"input#capture\").val(\"\");\n","  }\n","});\n","\n","load_next_tweet();\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1jCV5TEwPMK4"},"source":["with open(labels_filename, 'w') as outf:\n","    json.dump(labels, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW_OdI0uPMK_"},"source":["replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_dataset.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2eo0OufPMLG"},"source":["tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))\n","if os.path.exists(labels_filename):\n","    with open(labels_filename) as inf:\n","        labels = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4L08gpOPMLM"},"source":["dataset = [(tweet['id'], label) for label, tweet in zip(labels, tweets)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k56h31eaPMLV","outputId":"2c0a4a45-1487-401e-a78f-777d6289f217"},"source":["len(dataset), len(tweets), len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 1500, 1514)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"IH0aI3tAPMLf"},"source":["with open(replicable_dataset, 'w') as outf:\n","    json.dump(dataset, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUzE00rzPMLp"},"source":["tweet_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_python_tweets.json\")\n","labels_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_python_classes.json\")\n","replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_dataset.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxVywC15PMLw"},"source":["import json\n","with open(replicable_dataset) as inf:\n","    tweet_ids = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gS62Kt8QPML0"},"source":["actual_labels = []\n","label_mapping = dict(tweet_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HC-YAsxuPML6"},"source":["all_ids = [tweet_id for tweet_id, label in tweet_ids]\n","\n","with open(tweet_filename, 'a') as output_file:\n","    for start_index in range(0, len(all_ids), 100):\n","        id_string = \",\".join(str(i) for i in all_ids[start_index:start_index+100])\n","        \n","        search_results = t.statuses.lookup(_id=id_string)\n","        for tweet in search_results:\n","            if 'text' in tweet:\n","                # Valid tweet - save to file\n","                output_file.write(json.dumps(tweet))\n","                output_file.write(\"\\n\\n\")\n","                actual_labels.append(label_mapping[tweet['id']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OTI8JncPMMA"},"source":["with open(labels_filename, 'w') as outf:\n","    json.dump(actual_labels, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvtGTMD_PMMJ","outputId":"d6d83edf-5619-47bc-8ab5-ff2f3de77092"},"source":["len(actual_labels), len(all_ids)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 1500)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"gkJOAgasPMMS","outputId":"e34bb178-684b-4b18-b431-cf4a955b1ecc"},"source":["n_samples = min(len(tweets), len(labels))\n","sample_tweets = [t for t in tweets[:n_samples]]\n","labels = labels[:n_samples]\n","import numpy as np\n","y_true = np.array(labels)\n","print(\"{:.1f}% have class 1\".format(np.mean(y_true == 1) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["93.1% have class 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tVPSA6ArPMMX"},"source":["import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","import spacy\n","from sklearn.base import TransformerMixin\n","\n","\n","class BagOfWords(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X):\n","        results = []\n","        for document in X:\n","            row = {}\n","            for word in list(nlp(document, tag=False, parse=False, entity=False)):\n","                if len(word.text.strip()):\n","                    row[word.text] = True\n","            results.append(row)\n","        return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeiAlzLcPMMb"},"source":["from nltk import word_tokenize\n","\n","class NLTKBOW(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        return [{word: True for word in word_tokenize(document)}\n","                 for document in X]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"drKnlM3cPMMl"},"source":["from sklearn.feature_extraction import DictVectorizer\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","assert len(tweets) == len(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jElNJvSHPMMs","outputId":"402ddef0-0726-4238-ca4d-a9e1289bee1c"},"source":["import json\n","tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line)['text'])\n","print(\"Loaded {} tweets\".format(len(tweets)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 1500 tweets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxC45GamPMM0"},"source":["with open(classes_filename) as inf:\n","    labels = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYOUWbluPMM5"},"source":["n_samples = min(len(tweets), len(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ePo3Eh8PMNA"},"source":["sample_tweets = [t.lower() for t in tweets[:n_samples]]\n","labels = labels[:n_samples]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OT60_N7PMNE"},"source":["import numpy as np\n","y_true = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VEGs_x1PMNI","outputId":"a52d5872-565c-4278-95c8-6de802bbbf1c"},"source":["print(\"{:.1f}% have class 1\".format(np.mean(y_true == 1) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["93.1% have class 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kJgdsnYuPMNN"},"source":["from sklearn.base import TransformerMixin\n","from nltk import word_tokenize\n","\n","class NLTKBOW(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        return [{word: True for word in word_tokenize(document)}\n","                 for document in X]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s939VD4hPMNT","outputId":"722e14e7-c747-4de4-b638-f802df11c34e"},"source":["pipeline = Pipeline([('bag-of-words', NLTKBOW()),\n","                     ('vectorizer', DictVectorizer()),\n","                     ('naive-bayes', BernoulliNB())\n","                     ])\n","scores = cross_val_score(pipeline, sample_tweets, y_true, cv=10, scoring='f1')\n","print(\"Score: {:.3f}\".format(np.mean(scores)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Score: 0.939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSLOT30vPMNX","outputId":"bdc1c122-1ff3-4327-8d65-43126bfd9dc1"},"source":["scores"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.97560976, 0.97902098, 0.99644128, 0.96864111, 0.97887324,\n","       0.97526502, 0.96140351, 0.92418773, 0.75313808, 0.87452471])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"8am4djhTPMNc"},"source":["model = pipeline.fit(tweets, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrjvZVPxPMNh"},"source":["nb = model.named_steps['naive-bayes']\n","feature_probabilities = nb.feature_log_prob_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nO9jCICPMNm"},"source":["top_features = np.argsort(-nb.feature_log_prob_[1])[:50]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOBzr8oaPMNq"},"source":["dv = model.named_steps['vectorizer']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PyBOgPjPMNw","outputId":"9a05611c-8d44-4227-914a-fb5bfa01d895"},"source":["for i, feature_index in enumerate(top_features):\n","    print(i, dv.feature_names_[feature_index], np.exp(feature_probabilities[1][feature_index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : 0.8412017167381974\n","1 @ 0.6888412017167383\n","2 RT 0.565092989985694\n","3 # 0.4735336194563663\n","4 https 0.47281831187410567\n","5 Python 0.4492131616595135\n","6 , 0.23032904148783984\n","7 . 0.21244635193133052\n","8 and 0.19885550786838338\n","9 python 0.19742489270386257\n","10 to 0.18597997138769667\n","11 a 0.17954220314735328\n","12 with 0.15951359084406297\n","13 I 0.13662374821173104\n","14 is 0.13090128755364813\n","15 the 0.13018597997138767\n","16 my 0.12446351931330472\n","17 React 0.11874105865522179\n","18 ! 0.11158798283261803\n","19 this 0.10586552217453502\n","20 of 0.1044349070100143\n","21 for 0.1044349070100143\n","22 in 0.09084406294706723\n","23 like 0.08082975679542205\n","24 ; 0.08011444921316163\n","25 - 0.07796852646638053\n","26 The 0.07439198855507867\n","27 Analytics 0.07439198855507867\n","28 on 0.07367668097281832\n","29 & 0.07224606580829758\n","30 Docker 0.07010014306151648\n","31 AI 0.06723891273247495\n","32 CSS 0.06437768240343347\n","33 ( 0.0636623748211731\n","34 your 0.06294706723891276\n","35 ) 0.06294706723891276\n","36 If 0.06223175965665236\n","37 Jenkins 0.06223175965665236\n","38 HTML 0.061516452074391964\n","39 Developer 0.06080114449213163\n","40 BigData 0.05865522174535052\n","41 Learning 0.05793991416309015\n","42 AWS 0.057224606580829736\n","43 job 0.057224606580829736\n","44 not 0.057224606580829736\n","45 know 0.056509298998569386\n","46 it 0.056509298998569386\n","47 JavaScript 0.056509298998569386\n","48 looks 0.05436337625178827\n","49 * 0.05436337625178827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZJouZkePMN4"},"source":[""],"execution_count":null,"outputs":[]}]}