{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"datamining_assignment6_final.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Fdh4gvsOPMJV"},"source":["import twitter\n","import json\n","consumer_key = \"xzSXE5Fvx1ZL6P6PUNwXg56Ff\"\n","consumer_secret = \"9IgUnHkE2Pn0Di2v8HySatcryxuW6QtU7YNNJITT76LZM0puIP\"\n","access_token = \"393277154-vVEflsJ6aLcOUg8eJ9K8TBo1vMsJiYd9btPKv3p5\"\n","access_token_secret = \"iHR5QYIrOZ2v1mrvW20PjrpNcIvDNYmdorYpZHmz1HtXS\"\n","authorization = twitter.OAuth(access_token, access_token_secret, consumer_key, consumer_secret)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryIC_rk1PMJg"},"source":["import os\n","output_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_tweets.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7uGlsvkPMJo","outputId":"8bdbfaa0-3c03-4124-f4f1-14f18503a9bf"},"source":["t = twitter.Twitter(auth=authorization)\n","import json\n","with open(output_filename, 'a') as output_file:\n","    search_results = t.search.tweets(q=\"python\", count=1000)['statuses']\n","    for tweet in search_results:\n","        if 'text' in tweet:\n","            print(tweet['user']['screen_name'])\n","            print(tweet['text'])\n","            print()\n","            output_file.write(json.dumps(tweet))\n","            output_file.write(\"\\n\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LlnuxBot\n","RT @oaksjp: アメブロを更新しました。 『Apache2.2でpython2.7のmod_wsgiを動かす』 #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","hatebu100\n","あなたの Window 10 には何種類の Python が入っていますか？私は5種類でしたが。 - Qiita\n","https://t.co/OAuCDa1wnV\n","https://t.co/5GrXpvBJM9\n","タイトルは煽りです。… https://t.co/NYT7Ntgqfl\n","\n","Jeraylia_Takudo\n","RT @oaksjp: アメブロを更新しました。 『Apache2.2でpython2.7のmod_wsgiを動かす』 #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","avimimoun\n","RT @Radarinfo01: Online Courses - The Ultimate Beginner's Guide to Django 1.11 -&gt; https://t.co/IjSLDD9HhC\n","\n","#100DaysOfCode #html5 #NodeJs #A…\n","\n","kreutznaer2\n","RT @ethantenison: Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it automated t…\n","\n","oaksjp\n","アメブロを更新しました。 『Apache2.2でpython2.7のmod_wsgiを動かす』 #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","smaiitm\n","RT @gp_pulipaka: GANs Make an Entry Into High Energy Physics. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Py…\n","\n","learn__together\n","RT @ethantenison: Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it automated t…\n","\n","kreutznaer2\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","acobra334\n","@RealJamesWoods Monty Python ...omg\n","\n","ethantenison\n","Day 42: The censusdata package in #python is awesome. I'm coding cities as either urban or rural etc., and it autom… https://t.co/4Fc2zodV6a\n","\n","cool_python\n","RT @realpython: Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","akdm_bot\n","RT @gp_pulipaka: GANs Make an Entry Into High Energy Physics. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Py…\n","\n","tanakafreelance\n","「ディープラーニングですが、学ぼうと思うと高度な数学知識の必要性に意欲を挫かれることが少なくありません。本書はそんな方のために、高校レベルの数学とPythonの基本だけを前提に、実際に使えるディープラーニングを学ぶための入門書です… https://t.co/dP82ANUPEo\n","\n","MFuturetech\n","RT @gp_pulipaka: Implement Image classification by TensorFlow. #BigData #Analytics #DataScience #AI #MachineLearning #ComputerVision #IoT #…\n","\n","avimimoun\n","RT @jorgardev: React Styled Components: Inline Styles + 3 Other CSS Styling Approaches (with examples)\n","\n","#programming #programmer #developer…\n","\n","Comatose_D\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","AkiGlobe\n","@inu_love_global その気持ち、わかります。僕もIt業界に入ってSQLとPythonをやり始めました。\n","\n","SQLできるといろいろとデータ引き出してこれて、楽しいですよ。ミックさんの参考書が個人的にはおすすめですー。\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","codedailybot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","codedailybot\n","RT @iphonegalaxymd: When you are constantly anxious but you don't know why \n","\n","#coding #programming #programmer #code #developer #java #coder…\n","\n","RaymondWSA460\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineL…\n","\n","StormBear\n","Excellent article: #Python is eating the world: How one developer's side project became the hottest programming lan… https://t.co/Luc4wmCZJR\n","\n","Mike6338501\n","@RealJamesWoods You two are on another level with the Monty Python reference. Hadn’t seen that clip in a long time. Still funny.\n","\n","jasonhbush\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Dr…\n","\n","DeepSingularity\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineL…\n","\n","blackgaygemini\n","hmm maybe this summer I will figure out what \"digital humanities\" is/are and perhaps also become comfortable with Python\n","\n","Taieb_Bot\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineL…\n","\n","BigDataConda\n","RT @gp_pulipaka: AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI #MachineL…\n","\n","TheVeryHighKing\n","#Python #RaspberryPi #SpeedTest #Matplotlib https://t.co/SGpHXSnKaY\n","\n","TheVeryHighKing\n","Hourly average speed test results\n","-DL(Mb/s): 69.84 (max:70.20/min:69.30)\n","-UL(Mb/s): 19.39 (max:20.30/min:17.50)\n","-Pi… https://t.co/3DPFi4pmAH\n","\n","gp_pulipaka\n","AutoCompress: SOTA Automatic DNN Pruning for Ultra-High Compression Rates. \n","#BigData #Analytics #DataScience #AI… https://t.co/DaGMM2bHw5\n","\n","b4yu4ddi\n","RT @python_planet: Python Pandas Tutorial (Part 6): Add/Remove Rows and Columns From DataFrames\n","\n","☞ https://t.co/xWX3NdAXaN\n","\n","#python #progra…\n","\n","SorbiG\n","@patmon110 @xUndeadPikachu @desimojito @elonmusk No, I assume an octopus to be larger than the tiny mouth of that A… https://t.co/8CYsKthsIF\n","\n","ddbelcher\n","RT @realpython: Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","Mikelio_7\n","前に薬剤師と付き合った時に、共通言語みたいなものが無くて結局すぐ別れちゃったんですよ、自分が大変な時に分かってもらえなかったりして、僕はPythonでもJavaでもよかったんですけど\n","\n","xaelbot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","avimimoun\n","RT @ThePSF: Ontario Authors Python Group, Feb. 25 - Hobby Robotics with Nvidia Jetson Nano. Gerhard Roth covers what can be done with small…\n","\n","learn__together\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","k_can_python\n","@_L_6_ 真剣にやっていこうな\n","\n","Taieb_Bot\n","RT @thepydtyper: R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3…\n","\n","thepydtyper\n","R1D3 #100DaysOfCode #100DaysOfPython made a functional site with #Django and #Python! #webdev #FullStack 🤘 https://t.co/f3Tu5LoUvf\n","\n","subreddit_py\n","|Python World| Tutorials/Tips/Tricks for Python. https://t.co/9bivm3NER3\n","\n","BeardySmeardy\n","#Spectrum My #InternetSpeed :\n","Ping: 40.58 ms\n","Download: 198.71 Mbit/s\n","Upload: 10.92 Mbit/s\n","#automagic #python #corporateaccountability\n","\n","tomo_matsushi\n","Scalaが衰退してるとかの話はこの方が発端？\n","ScalaユーザがJavaユーザやPythonユーザぐらいになったら盛り上がった！\n","なので、そもそも盛り上がってないものを衰退したってのもね‥\n","言語としては後初のScalaのほうが素… https://t.co/J9PJ778kFt\n","\n","k_can_python\n","@yamada_marumaru おはよ💕\n","\n","Deep_In_Depth\n","Large Scale Training at BAIR with Ray Tune https://t.co/0o5JfUG1kJ #DeepLearning #NeuralNetworks… https://t.co/zg40VHIo9I\n","\n","nondakure180\n","Python + Excel に興味あり\n","\n","Cryptocristian\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic ra…\n","\n","jorgardev\n","React Styled Components: Inline Styles + 3 Other CSS Styling Approaches (with examples)\n","\n","#programming #programmer… https://t.co/wQT5MtNZRG\n","\n","AlmanafSivi\n","RT @KirkDBorne: Must get this “ML from A to Z” book — I now have my copy &amp; I love it! &gt;&gt; \"Mastering #MachineLearning #Algorithms\" (2nd Edit…\n","\n","FullstackDevJS\n","Shopyo: Enhance Your Flask by Exploring An Advanced Flask App #Fullstack #Javascript #Angular #React #Python https://t.co/zjdcke8dik\n","\n","realpython\n","Refactoring and Asking for Forgiveness #python https://t.co/YDe04YFrex\n","\n","avimimoun\n","RT @ThePSF: Boulder, CO Python Meetup March 10 - Boulder, CO. Talks include: Keeping credentials safe in the GitHub age (Matt Bacchi) &amp; Usi…\n","\n","ProgramWithUsNY\n","pandas_merge with inner join \n"," \n","#programwithus #python https://t.co/k0JNSa6uLg\n","\n","umibedessk\n","✏️プログラミング学習12日目✏️\n","つまらないと思って学習すると、脳も不必要な情報と判断してしまって記憶の定着がしにくくなるそうです。\n","興味を持って学習をしていきます！\n","\n","#今日の積み上げ\n","👉Python\n","👉Progate\n","👉読書… https://t.co/TgbWJS4Hm0\n","\n","Softtek\n","#Python continues to be the favorite #programming language among #developers https://t.co/lS797ClZ8z\n","\n","orekyuu\n","某ゆーちゅーばーがScala disしてると聞いて見てみたけど、人口が右肩下がりになった言語がまたもどることは過去の例からもまずないって言うけど、Pythonとか一時期Rubyに食われたけど、今また人気出てません？\n","\n","HeresJolly\n","Burmese Python Sanders\n","\n","y_yunusa4\n","RT @faruqjada: Today our SPECIAL SESSION on Python for Data Science was successful.\n","#1m_AI_talents_in_10yrs https://t.co/DBqG27STby\n","\n","KC_Gosso\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Dr…\n","\n","cool_python\n","RT @MrDataScience: The History of Top Programming Languages from 1965 to 2019! #Coding #DataScience #Analytics #IoT #Python\n","https://t.co/da…\n","\n","LlnuxBot\n","RT @oaksjp: アメブロを更新しました。 『python2.7でmod_wsgiを動かす』 #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","rstatstweet\n","RT @gp_pulipaka: Implement Image classification by TensorFlow. #BigData #Analytics #DataScience #AI #MachineLearning #ComputerVision #IoT #…\n","\n","A_Retweeter_Boy\n","Realtime Bitcoin Track with Python.......\n","\n","#Python3 #Bitcoin #bitcoin \n","\n","@hackeroid_ @utsavtechie @stufflistings… https://t.co/L9CRg2KO4C\n","\n","HariSeldoon\n","RT @KirkDBorne: 🌟The 3rd edition of this massive book is now here! &gt;&gt; “#Python #MachineLearning — ML and #DeepLearning with Python, scikit-…\n","\n","kaji_blog\n","【 #python 参照 】\n","\n","#ブログ更新\n","\n","今回はpythonにおける参照について\n","\n","✅参照の概念\n","\n","✅参照を\"渡す\"\n","\n","✅copy()、deepcopy()関数\n","\n","この参照を理解すると、リストや辞書への考え方が大きく変わりま… https://t.co/p3rjbt0ZEa\n","\n","rsk0315_h4x\n","知ってる！ C に慣れた人が C 風のコードを Python で書いて汚くなるやつだ！\n","\n","DavFields\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic ra…\n","\n","oaksjp\n","アメブロを更新しました。 『python2.7でmod_wsgiを動かす』 #LINUX #PYTHON\n","https://t.co/35E0Lm6FQx\n","\n","AlmanafSivi\n","RT @gp_pulipaka: Measuring Compositional Generalization. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Python…\n","\n","vishn_u99\n","RT @Radarinfo01: Online Courses - The Ultimate Beginner's Guide to Django 1.11 -&gt; https://t.co/IjSLDD9HhC\n","\n","#100DaysOfCode #html5 #NodeJs #A…\n","\n","JayInfoSec\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Dr…\n","\n","thelovelymedusa\n","@MnFrost Ball Python!\n","\n","xdubyaa\n","RT @shelbylcole: Progressive digital job postings be like:\n","ℜ𝔢𝔮𝔲𝔦𝔯𝔢𝔪𝔢𝔫𝔱𝔰:\n","- 7+ years at campaigns or agencies\n","- copywriter \n","- video editer\n","-…\n","\n","EmerensB\n","この記事に曰く\n","https://t.co/b3jP56hJqb\n","\n","HTML,CSS,JS, Python 等の比較的\"easy\"な言語は4~6ヶ月で基礎を習得できる\n","\n","個人的な解釈は「それぐらい勉強したら早くプロダクト開発に進もう… https://t.co/VOUWew2w7c\n","\n","BSUPimp\n","RT @gp_pulipaka: Measuring Compositional Generalization. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Python…\n","\n","BlkHwk0ps\n","RT @advait_me: Logistic Regression : Part 1 : Machine Learning \n","#bigdata #data #deeplearning #tech #coding  #python #programming  #analytic…\n","\n","reversepython\n","RT @MrDataScience: The History of Top Programming Languages from 1965 to 2019! #Coding #DataScience #Analytics #IoT #Python\n","https://t.co/da…\n","\n","MFuturetech\n","RT @advait_me: Logistic Regression : Part 1 : Machine Learning \n","#bigdata #data #deeplearning #tech #coding  #python #programming  #analytic…\n","\n","task_c_lang\n","#Bot\n","#대리과제\n","#컴공과제\n","#과제 \n","#프로그래밍\n","프로그래밍과제 해드립니다.\n","저렴한 가격에 해드리니 많은 이용 부탁드립니다!\n","자세한 문의는 디엠주세요!!\n","주력은 알고리즘이고,\n","언어는 python,c 가능합니다.\n","\n","Vaelot1\n","RT @GaelVaroquaux: Pypi, the Python package repository, costs 800k$/month in hosting: the volume that it serves brings real costs. \n","\n","Side n…\n","\n","MD_Connolly\n","RT @shelbylcole: Progressive digital job postings be like:\n","ℜ𝔢𝔮𝔲𝔦𝔯𝔢𝔪𝔢𝔫𝔱𝔰:\n","- 7+ years at campaigns or agencies\n","- copywriter \n","- video editer\n","-…\n","\n","masonrothman\n","RT @Keiko_geo: Something different this time. \"Interactive #maps on #python #JupyterNotebook\" #folium #ipyleaflet What else is out there? D…\n","\n","PedPrac12\n","RT @Starkeneurosurg: CHILD NECK PYTHON: Parents reported there giant snake in neck. Fistula direct connection artery &amp; vein. Veins dilated…\n","\n","Kazansky1\n","RT @f_calandra: À la rencontre des habitants du quartier Python-Duvernois. Nous avons échangé notamment sur les questions de propreté et su…\n","\n","piasu_iyaring8\n","@haku_1123 そそ\n","まだPythonまで行けてないけどw\n","\n","vlgermanov\n","RT @jpetazzo: I had bookmarked @nnja's talk about Python debugging a while ago, and I finally took the time to watch it. \n","\n","Video:\n","https://t…\n","\n","arch_update_bot\n","python-atspi 2.36.0-1 (any/Extra)\n","\"Python bindings for D-Bus AT-SPI\"\n","&lt;2020-03-08&gt;\n","\n","leidavirginia1\n","RT @CiscoDevNet: Building a network automation controller in Python.\n","https://t.co/EM91RBqrsw\n","Join @dmfigol  Sunday, March 8th, 6 PM CET. 1…\n","\n","TDataScience\n","Finding cyclic patterns: a tutorial on how to implement STFT in Python by Tiago Silveira https://t.co/uU1UGKGZsX\n","\n","asa9no640511\n","RT @Cpp_Learning: 時系列データの前処理(ラグ特徴量)についてブログ記事を書きました。\n","\n","pythonのソースコード付きで解説してますので、良ければ参考にして下さいね。\n","\n","【機械学習】時系列データの前処理 -ラグ特徴量作成- https://t.co/cR0ft…\n","\n","haku_1123\n","@piasu_iyaring8 プログラミング言語？Pythonとか？\n","\n","softqueerfeels\n","RT @catalinmpit: If your job spec looks like this:\n","\n","* HTML, CSS\n","* JavaScript, Python\n","* NodeJS, GraphQL\n","* React\n","* AWS\n","* Docker\n","* Jenkins, Dr…\n","\n","RauceWine\n","RT @ChristinaPhili5: Based on my Twitter everyone I know is hoarding Purell, zooming into coffee chats and calculating the probabilistic ra…\n","\n","hubofml\n","RT @machinelearnflx: Unsupervised Machine Learning Hidden Markov Models in Python https://t.co/Yg3Zj81gHc  #machinelearning #ad\n","\n","0xhexhex\n","RT @machinelearnflx: Unsupervised Machine Learning Hidden Markov Models in Python https://t.co/Yg3Zj81gHc  #machinelearning #ad\n","\n","lululevi\n","RT @ajhtweeting: This Python style video editing is a hoot! I call this one \"Inside Trump's Head\". &lt;sound up&gt; #TrumpPeedHisPants #TrumpViru…\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C73gSQUEPMJy","outputId":"11e1948b-b97d-4f32-be78-6b1c5f80ba75"},"source":["n_output = 0\n","\n","with open(output_filename, 'a') as output_file:\n","    search_results = t.search.tweets(q=\"python\", count=1000)['statuses']\n","    for tweet in search_results:\n","        if 'text' in tweet:\n","            output_file.write(json.dumps(tweet))\n","            output_file.write(\"\\n\\n\")\n","            n_output += 1\n","\n","print(\"Saved {} entries\".format(n_output))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved 100 entries\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DIxRrZOrPMJ6"},"source":["import os\n","input_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_tweets.json\")\n","classes_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_classes.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_QGrY_3PMKC"},"source":["labels_filename = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"python_classes.json\")\n","tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCG2B3CRPMKI","outputId":"e997d29a-1def-408b-e0e4-71b234cf7bb4"},"source":["tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))\n","print(\"Loaded {} tweets\".format(len(tweets)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 1500 tweets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZwkH_sv0PMKQ","outputId":"e7690c2d-8fc8-4112-aa67-a18c923e1d92"},"source":["tweet_sample = tweets\n","labels = []\n","if os.path.exists(classes_filename):\n","    with open(classes_filename) as inf:\n","        labels = json.load(inf)\n","print(len(labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_r89ZfFwPMKW"},"source":["def get_next_tweet():\n","    return tweets[len(labels)]['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RYqtVHJPMKd","outputId":"a7f195e5-972b-46b5-b983-13e321c08eac"},"source":["%%html\n","<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","\n","<script>\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_next_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n","\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","      if(e.which == 48) {\n","        // 0 pressed\n","        set_label(0);\n","        $(\"input#capture\").val(\"\");\n","      }else if (e.which == 49){\n","        // 1 pressed\n","        set_label(1);  \n","        $(\"input#capture\").val(\"\");\n","      }\n","});\n","\n","load_next_tweet();\n","</script>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","\n","<script>\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_next_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n","\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","      if(e.which == 48) {\n","        // 0 pressed\n","        set_label(0);\n","        $(\"input#capture\").val(\"\");\n","      }else if (e.which == 49){\n","        // 1 pressed\n","        set_label(1);  \n","        $(\"input#capture\").val(\"\");\n","      }\n","});\n","\n","load_next_tweet();\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HjczxBhGPMKo","outputId":"ff5b9a59-e544-49d5-f9ce-86879bfb469e"},"source":["%%javascript\n","\n","\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","\n","function set_label(label){\n","    var kernel = IPython.notebook.kernel;\n","    kernel.execute(\"labels.append(\" + label + \")\");\n","    load_next_tweet();\n","}\n","\n","function load_next_tweet(){\n","   var code_input = \"get_tweet()\";\n","   var kernel = IPython.notebook.kernel;\n","   var callbacks = { 'iopub' : {'output' : handle_output}};\n","   kernel.execute(code_input, callbacks, {silent:false});\n","}\n","\n","function handle_output(out){\n","   console.log(out);\n","   var res = out.content.data[\"text/plain\"];\n","   $(\"div#tweet_text\").html(res);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"BBBLEPYGPMKx","outputId":"4134a854-d18c-42c7-adf5-38e8a221deb0"},"source":["%%html\n","<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","<script>\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","  if(e.which == 48) {\n","    // 0 pressed\n","    set_label(0);\n","    $(\"input#capture\").val(\"\");\n","  }else if (e.which == 49){\n","    // 1 pressed\n","    set_label(1);  \n","    $(\"input#capture\").val(\"\");\n","  }\n","});\n","\n","load_next_tweet();\n","</script>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div name=\"tweetbox\">\n","    Instructions: Click in text box. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n","    Tweet: <div id=\"tweet_text\" value=\"text\"></div><br>\n","    <input type=text id=\"capture\"></input><br>\n","</div>\n","<script>\n","$(\"input#capture\").keypress(function(e) {\n","    console.log(e);\n","  if(e.which == 48) {\n","    // 0 pressed\n","    set_label(0);\n","    $(\"input#capture\").val(\"\");\n","  }else if (e.which == 49){\n","    // 1 pressed\n","    set_label(1);  \n","    $(\"input#capture\").val(\"\");\n","  }\n","});\n","\n","load_next_tweet();\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"1jCV5TEwPMK4"},"source":["with open(labels_filename, 'w') as outf:\n","    json.dump(labels, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW_OdI0uPMK_"},"source":["replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"twitter\", \"replicable_dataset.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2eo0OufPMLG"},"source":["tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line))\n","if os.path.exists(labels_filename):\n","    with open(labels_filename) as inf:\n","        labels = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4L08gpOPMLM"},"source":["dataset = [(tweet['id'], label) for label, tweet in zip(labels, tweets)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k56h31eaPMLV","outputId":"2c0a4a45-1487-401e-a78f-777d6289f217"},"source":["len(dataset), len(tweets), len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 1500, 1514)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"IH0aI3tAPMLf"},"source":["with open(replicable_dataset, 'w') as outf:\n","    json.dump(dataset, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUzE00rzPMLp"},"source":["tweet_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_python_tweets.json\")\n","labels_filename = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_python_classes.json\")\n","replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"data\", \"twitter\", \"replicable_dataset.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxVywC15PMLw"},"source":["import json\n","with open(replicable_dataset) as inf:\n","    tweet_ids = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gS62Kt8QPML0"},"source":["actual_labels = []\n","label_mapping = dict(tweet_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HC-YAsxuPML6"},"source":["all_ids = [tweet_id for tweet_id, label in tweet_ids]\n","\n","with open(tweet_filename, 'a') as output_file:\n","    for start_index in range(0, len(all_ids), 100):\n","        id_string = \",\".join(str(i) for i in all_ids[start_index:start_index+100])\n","        \n","        search_results = t.statuses.lookup(_id=id_string)\n","        for tweet in search_results:\n","            if 'text' in tweet:\n","                # Valid tweet - save to file\n","                output_file.write(json.dumps(tweet))\n","                output_file.write(\"\\n\\n\")\n","                actual_labels.append(label_mapping[tweet['id']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OTI8JncPMMA"},"source":["with open(labels_filename, 'w') as outf:\n","    json.dump(actual_labels, outf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvtGTMD_PMMJ","outputId":"d6d83edf-5619-47bc-8ab5-ff2f3de77092"},"source":["len(actual_labels), len(all_ids)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1500, 1500)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"gkJOAgasPMMS","outputId":"e34bb178-684b-4b18-b431-cf4a955b1ecc"},"source":["n_samples = min(len(tweets), len(labels))\n","sample_tweets = [t for t in tweets[:n_samples]]\n","labels = labels[:n_samples]\n","import numpy as np\n","y_true = np.array(labels)\n","print(\"{:.1f}% have class 1\".format(np.mean(y_true == 1) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["93.1% have class 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tVPSA6ArPMMX"},"source":["import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","import spacy\n","from sklearn.base import TransformerMixin\n","\n","\n","class BagOfWords(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X):\n","        results = []\n","        for document in X:\n","            row = {}\n","            for word in list(nlp(document, tag=False, parse=False, entity=False)):\n","                if len(word.text.strip()):\n","                    row[word.text] = True\n","            results.append(row)\n","        return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeiAlzLcPMMb"},"source":["from nltk import word_tokenize\n","\n","class NLTKBOW(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        return [{word: True for word in word_tokenize(document)}\n","                 for document in X]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"drKnlM3cPMMl"},"source":["from sklearn.feature_extraction import DictVectorizer\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","assert len(tweets) == len(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jElNJvSHPMMs","outputId":"402ddef0-0726-4238-ca4d-a9e1289bee1c"},"source":["import json\n","tweets = []\n","with open(input_filename) as inf:\n","    for line in inf:\n","        if len(line.strip()) == 0:\n","            continue\n","        tweets.append(json.loads(line)['text'])\n","print(\"Loaded {} tweets\".format(len(tweets)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 1500 tweets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hxC45GamPMM0"},"source":["with open(classes_filename) as inf:\n","    labels = json.load(inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYOUWbluPMM5"},"source":["n_samples = min(len(tweets), len(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ePo3Eh8PMNA"},"source":["sample_tweets = [t.lower() for t in tweets[:n_samples]]\n","labels = labels[:n_samples]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OT60_N7PMNE"},"source":["import numpy as np\n","y_true = np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VEGs_x1PMNI","outputId":"a52d5872-565c-4278-95c8-6de802bbbf1c"},"source":["print(\"{:.1f}% have class 1\".format(np.mean(y_true == 1) * 100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["93.1% have class 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kJgdsnYuPMNN"},"source":["from sklearn.base import TransformerMixin\n","from nltk import word_tokenize\n","\n","class NLTKBOW(TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        return [{word: True for word in word_tokenize(document)}\n","                 for document in X]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s939VD4hPMNT","outputId":"722e14e7-c747-4de4-b638-f802df11c34e"},"source":["pipeline = Pipeline([('bag-of-words', NLTKBOW()),\n","                     ('vectorizer', DictVectorizer()),\n","                     ('naive-bayes', BernoulliNB())\n","                     ])\n","scores = cross_val_score(pipeline, sample_tweets, y_true, cv=10, scoring='f1')\n","print(\"Score: {:.3f}\".format(np.mean(scores)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Score: 0.939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSLOT30vPMNX","outputId":"bdc1c122-1ff3-4327-8d65-43126bfd9dc1"},"source":["scores"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.97560976, 0.97902098, 0.99644128, 0.96864111, 0.97887324,\n","       0.97526502, 0.96140351, 0.92418773, 0.75313808, 0.87452471])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"8am4djhTPMNc"},"source":["model = pipeline.fit(tweets, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrjvZVPxPMNh"},"source":["nb = model.named_steps['naive-bayes']\n","feature_probabilities = nb.feature_log_prob_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nO9jCICPMNm"},"source":["top_features = np.argsort(-nb.feature_log_prob_[1])[:50]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOBzr8oaPMNq"},"source":["dv = model.named_steps['vectorizer']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PyBOgPjPMNw","outputId":"9a05611c-8d44-4227-914a-fb5bfa01d895"},"source":["for i, feature_index in enumerate(top_features):\n","    print(i, dv.feature_names_[feature_index], np.exp(feature_probabilities[1][feature_index]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : 0.8412017167381974\n","1 @ 0.6888412017167383\n","2 RT 0.565092989985694\n","3 # 0.4735336194563663\n","4 https 0.47281831187410567\n","5 Python 0.4492131616595135\n","6 , 0.23032904148783984\n","7 . 0.21244635193133052\n","8 and 0.19885550786838338\n","9 python 0.19742489270386257\n","10 to 0.18597997138769667\n","11 a 0.17954220314735328\n","12 with 0.15951359084406297\n","13 I 0.13662374821173104\n","14 is 0.13090128755364813\n","15 the 0.13018597997138767\n","16 my 0.12446351931330472\n","17 React 0.11874105865522179\n","18 ! 0.11158798283261803\n","19 this 0.10586552217453502\n","20 of 0.1044349070100143\n","21 for 0.1044349070100143\n","22 in 0.09084406294706723\n","23 like 0.08082975679542205\n","24 ; 0.08011444921316163\n","25 - 0.07796852646638053\n","26 The 0.07439198855507867\n","27 Analytics 0.07439198855507867\n","28 on 0.07367668097281832\n","29 & 0.07224606580829758\n","30 Docker 0.07010014306151648\n","31 AI 0.06723891273247495\n","32 CSS 0.06437768240343347\n","33 ( 0.0636623748211731\n","34 your 0.06294706723891276\n","35 ) 0.06294706723891276\n","36 If 0.06223175965665236\n","37 Jenkins 0.06223175965665236\n","38 HTML 0.061516452074391964\n","39 Developer 0.06080114449213163\n","40 BigData 0.05865522174535052\n","41 Learning 0.05793991416309015\n","42 AWS 0.057224606580829736\n","43 job 0.057224606580829736\n","44 not 0.057224606580829736\n","45 know 0.056509298998569386\n","46 it 0.056509298998569386\n","47 JavaScript 0.056509298998569386\n","48 looks 0.05436337625178827\n","49 * 0.05436337625178827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZJouZkePMN4"},"source":[""],"execution_count":null,"outputs":[]}]}